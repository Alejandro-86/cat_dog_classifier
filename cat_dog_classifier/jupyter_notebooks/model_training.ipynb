{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model.\n",
    "This notebook will be used to train and evaluate the model. We will do the following steps:\n",
    "\n",
    "1. Load and transform the data\n",
    "2. Load the data in batches using a custom data generator (Dataloader)\n",
    "3. Define train and test functions\n",
    "4. Define the model architecture and train loop while visualizing the loss and accuracy of the model.\n",
    "6. Evaluate the trained model on the test set\n",
    "7. Save the trained model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and transform the data\n",
    "\n",
    "In this step we will load the data and split it into training, validation and testing sets.\n",
    "\n",
    "We will split the training set into 80% training and 20% validation sets and and use the test set to evaluate the model after training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "trans = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    # T.RandomRotation(15),\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset from disk\n",
    "data_dir = \"../dataset\"\n",
    "train_dir = os.path.join(data_dir, \"training_set\")\n",
    "test_dir = os.path.join(data_dir, \"test_set\")\n",
    "training_set = ImageFolder(train_dir, transform=trans)\n",
    "test_set = ImageFolder(test_dir, transform=trans)\n",
    "\n",
    "# Split training dataset into training and validation sets\n",
    "train_size = int(0.8 * len(training_set))  # 80% for training\n",
    "val_size = len(training_set) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(training_set, [train_size, val_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data in batches using a custom data generator (Dataloader)\n",
    "\n",
    "We create a custom data generator to load the data in batches. This is done to avoid loading the entire dataset into memory at once. We will use the data generator to load the training, validation and testing data and sending the batch to the GPU (if available) for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "from torch.backends.mps import is_available as mps_is_available\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda import is_available\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if is_available()\n",
    "    else \"mps\"\n",
    "    if mps_is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class CustomDataLoader(DataLoader):\n",
    "    def __iter__(self):\n",
    "        for batch in tqdm(super(CustomDataLoader, self).__iter__(), unit='batch', dynamic_ncols=True):\n",
    "            yield [item.to(device) if isinstance(item, torch.Tensor) else item for item in batch]\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "\n",
    "params = {\"batch_size\": 64, \"shuffle\": True}\n",
    "train_loader = CustomDataLoader(train_dataset, **params)\n",
    "val_loader = CustomDataLoader(val_dataset, **params)\n",
    "test_loader = CustomDataLoader(test_set, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Define train and test functions\n",
    "\n",
    "We define the train and test functions to train and evaluate the model. The train function will be used to train the model on the training set and the test function will be used to evaluate the model on the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import float as torch_float\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0 and batch > 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch_float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss, 100*correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the model architecture and train the model\n",
    "\n",
    "We define the model architecture and train the model on the training set. We will use the SGD optimizer and the Cross Entropy Loss function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.84batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 2:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.85batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 3:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:35<00:00,  1.91batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 4:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.85batch/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  2.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 5:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:37<00:00,  1.81batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 6:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.84batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 7:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.82batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 8:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:35<00:00,  1.87batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 9:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:35<00:00,  1.90batch/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  2.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 10:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:35<00:00,  1.90batch/s]\n",
      "100%|██████████| 17/17 [00:05<00:00,  2.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 11:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:34<00:00,  1.92batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 12:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:36<00:00,  1.83batch/s]\n",
      "100%|██████████| 17/17 [00:06<00:00,  2.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Epoch 13:  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 46/67 [00:24<00:11,  1.87batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m:  \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     loss_train \u001b[39m=\u001b[39m train(train_loader, model, loss_fn, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mtrain_loss/batch\u001b[39m\u001b[39m\"\u001b[39m, loss_train, t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     loss_validation, accuracy_validation \u001b[39m=\u001b[39m test(val_loader, model, loss_fn)\n",
      "\u001b[1;32m/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n",
      "\u001b[1;32m/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(\u001b[39msuper\u001b[39m(CustomDataLoader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m(), unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m, dynamic_ncols\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexalonso/PycharmProjects/cat_dog_classifier/cat_dog_classifier/jupyter_notebooks/model_training.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39myield\u001b[39;00m [item\u001b[39m.\u001b[39mto(device) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch]\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/torchvision/datasets/folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(f)\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/PIL/Image.py:916\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    869\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m    870\u001b[0m ):\n\u001b[1;32m    871\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    918\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\n\u001b[1;32m    919\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    920\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/cat_dog_classifier/.venv/lib/python3.10/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "# Load pretrained ResNet-18 model\n",
    "model = resnet18().to(device)\n",
    "\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "# Loss functions specified in the torch.nn package\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# training loop\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}:  \")\n",
    "    loss_train = train(train_loader, model, loss_fn, optimizer)\n",
    "    writer.add_scalar(\"train/loss\", loss_train, t)\n",
    "    loss_validation, accuracy_validation = test(val_loader, model, loss_fn)\n",
    "    writer.add_scalar(\"validation/loss\", loss_validation, t)\n",
    "    writer.add_scalar(\"validation/accuracy\", accuracy_validation, t)\n",
    "    print(\"-------------------------------\")\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training complete! \\n ------------------------------- \\nComputing test error...\")\n",
    "test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
